import numpy as np

import pandas as pd

import gc

import os

import matplotlib.pyplot as plt

import seaborn as sns

import plotly.express as px

import tensorflow as tf

import tensorflow.keras

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, RNN, GRU

from tensorflow.keras.optimizers import Adam

from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

from tensorflow.keras.regularizers import l2

from tensorflow.keras.utils import to_categorical

from sklearn.metrics import mean_absolute_error, mean_squared_error

from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict

from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler

from sklearn.feature_selection import SelectFromModel, SelectKBest, RFE, chi2

from sklearn.feature_selection import VarianceThreshold

from sklearn.model_selection import RepeatedStratifiedKFold

from sklearn.svm import LinearSVC

from sklearn.linear_model import LogisticRegression, LassoCV

from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, IsolationForest

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix, explained_variance_score

from sklearn.model_selection import KFold

from imblearn.under_sampling import RandomUnderSampler

df = pd.read_csv("Darknet.CSV", keep_default_na = False,low_memory = False, error_bad_lines = False)

df.head()

df.sample(10)

df.info()

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)

    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))

    return df

reduce_mem_usage(df)

df.info()

df.rename(columns = {"Label" : "Type", "Label.1" : "Subtype"}, inplace = True)

df

type_vc = df["Type"].value_counts()

px.bar(type_vc, x=type_vc.index, y = type_vc.values,
           color=type_vc.index, title="Dataset Type Wise Count",
          labels={'y': "Type Count", 'index': "Type Name"}, color_discrete_sequence=px.colors.qualitative.G10)

subtype_vc = df["Subtype"].value_counts()

px.bar(subtype_vc, x=subtype_vc.index, y = subtype_vc.values,
           color=subtype_vc.index, title="Dataset Sub Type Wise Count",
          labels={'y': "Sub Type Count", 'index': "Sub Type Name"}, color_discrete_sequence=px.colors.qualitative.T10)

df.groupby("Type")["Subtype"].unique()

df.groupby("Type")["Subtype"].nunique()

df["Subtype"].loc[df["Subtype"] == "AUDIO-STREAMING"] = "Streaming"

df["Subtype"].loc[df["Subtype"] == "File-transfer"] = "File-Transfer"

df["Subtype"].loc[df["Subtype"] == "Video-streaming"] = "Streaming"
df["Subtype"].loc[df["Subtype"] == "Video-Streaming"] = "Streaming"
df["Subtype"].loc[df["Subtype"] == "Audio-Streaming"] = "Streaming"

df["Subtype"].loc[df["Subtype"] == "Chat"] = "Data-Transfer"
df["Subtype"].loc[df["Subtype"] == "Email"] = "Data-Transfer"
df["Subtype"].loc[df["Subtype"] == "VOIP"] = "Data-Transfer"
df["Subtype"].loc[df["Subtype"] == "File-Transfer"] = "Data-Transfer"

subtype_vc = df["Subtype"].value_counts()

px.bar(subtype_vc, x=subtype_vc.index, y = subtype_vc.values,
           color=subtype_vc.index, title="Dataset Sub Type Wise Count",
          labels={'y': "Sub Type Count", 'index': "Sub Type Name"}, color_discrete_sequence=px.colors.qualitative.T10)



df.groupby("Type")["Subtype"].value_counts()

df.groupby("Type")["Subtype"].nunique()

df.loc[:, "Encryption"] = ''

df

df["Encryption"].loc[df["Type"] == "Non-Tor"] = "Standard"

df["Encryption"].loc[df["Type"] == "NonVPN"] = "Standard"

df["Encryption"].loc[df["Type"] == "Tor"] = "High"

df["Encryption"].loc[df["Type"] == "VPN"] = "High"

df

df.isnull().sum()

df.replace([np.inf, -np.inf], np.nan, inplace=True)

df.isnull().sum().sum()

df.info()

df["Encryption"]

df["Encryption"] = df["Encryption"].map({"Standard":0,"High":1})

df.info()

df.dropna(inplace=True)

y = df["Subtype"]

le = LabelEncoder()

y = le.fit_transform(y)

X = df.select_dtypes(exclude=["object"])

X.info()

num_features_opt = 25

num_features_max = 35

features_best = []

lsvc = LinearSVC(C=0.1, penalty="l1", dual=False).fit(X, y)

model = SelectFromModel(lsvc, prefit=True)

X_new = model.transform(X)

X_selected_df = pd.DataFrame(X_new, columns=[X.columns[i] for i in range(len(X.columns)) if model.get_support()[i]])

features_best.append(X_selected_df.columns.tolist())

lasso = LassoCV(cv=3).fit(X, y)
model = SelectFromModel(lasso, prefit=True)
X_new = model.transform(X)
X_selected_df = pd.DataFrame(X_new, columns=[X.columns[i] for i in range(len(X.columns)) if model.get_support()[i]])
features_best.append(X_selected_df.columns.tolist())

X

bestfeatures = SelectKBest()
fit = bestfeatures.fit(X, y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)

rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_features_max, step=10, verbose=5)
rfe_selector.fit(X, y)
rfe_support = rfe_selector.get_support()
rfe_feature = X.loc[:,rfe_support].columns.tolist()
features_best.append(rfe_feature)

selector = VarianceThreshold(threshold=10)
np.shape(selector.fit_transform(X))
features_best.append(list(np.array(X.columns)[selector.get_support(indices=False)]))

main_cols = []
main_cols_opt = {feature_name : 0 for feature_name in df.columns.tolist()}
for i in range(len(features_best)):
    for feature_name in features_best[i]:
        main_cols_opt[feature_name] += 1

df_main_cols_opt = pd.DataFrame.from_dict(main_cols_opt, orient='index', columns=['Num'])
df_main_cols_opt.sort_values(by=['Num'], ascending=False)

main_cols = df_main_cols_opt.nlargest(num_features_opt, 'Num').index.tolist()

main_cols

X = df[main_cols]

base_models = [("ADA_model", AdaBoostClassifier(random_state=42)),
               ("RF_model", RandomForestClassifier(random_state=42,n_jobs=-1)),
               ("GB_model", GradientBoostingClassifier(random_state=42)),
               ("ET_model", ExtraTreesClassifier(random_state=42)),
               ("IF_model",IsolationForest(random_state=42))]

kfolds = 4

split = KFold(n_splits=kfolds, shuffle=True, random_state=42)

for name, model in base_models:
    cv_results = cross_val_score(model,
                                 X, y,
                                 cv=split,
                                 scoring="accuracy",
                                 n_jobs=-1)
    min_score = round(min(cv_results), 4)
    max_score = round(max(cv_results), 4)
    mean_score = round(np.mean(cv_results), 4)
    std_dev = round(np.std(cv_results), 4)
    print(f"{name} cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}, ")



X = df[['Src Port',
 'Dst Port',
 'Total Fwd Packet',
 'Total Bwd packets',
 'Fwd Header Length',
 'Bwd Header Length',
 'Fwd Packets/s',
 'Bwd Packets/s',
 'ACK Flag Count',
 'FWD Init Win Bytes',
 'Bwd Init Win Bytes',
 'Protocol',
 'Flow Duration',
 'Total Length of Fwd Packet',
 'Total Length of Bwd Packet',
 'Fwd Packet Length Max',
 'Fwd Packet Length Min',
 'Fwd Packet Length Mean',
 'Fwd Packet Length Std',
 'Bwd Packet Length Max',
 'Bwd Packet Length Min',
 'Bwd Packet Length Mean',
 'Bwd Packet Length Std',
 'Flow Packets/s',
 'Flow IAT Mean']]

y = df["Subtype"]

y = le.fit_transform(y)

y = to_categorical(y)

rus = RandomUnderSampler(random_state=1)

X_sampled, y_sampled = rus.fit_resample(X, y)

X_sampled.shape, y_sampled.shape

ss = StandardScaler()

X_scaled = ss.fit_transform(X_sampled)

X_scaled

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_sampled, test_size=0.20, random_state=42, stratify=y_sampled)

X_train.shape

def create_model():
    model = Sequential()
    model.add(LSTM(input_shape=(25, 1), units=512, activation='relu',return_sequences=False, return_state=False,))
    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))
    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))
    model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'softmax'))
    return model

model = create_model()

model.compile(loss='categorical_crossentropy', metrics=["accuracy"], optimizer="adam")

model.summary()

#X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)

X_train.shape

history = model.fit(x = X_train, y = y_train, batch_size=256, validation_split=0.2, verbose=1, epochs = 20)

epochs = range(1, len(history.history["loss"]) + 1)

plt.rcParams["figure.figsize"] = (10,6)

train_loss = history.history["loss"]
train_acc = history.history["accuracy"]
plt.plot(epochs, train_loss, "-b", label = "Training Loss")
plt.plot(epochs, train_acc, "--b", label = "Training Accuracy")

val_los = history.history["val_loss"]
val_acc = history.history["val_accuracy"]
plt.plot(epochs, val_los, "-g", label = "Validation Loss")
plt.plot(epochs, val_acc, "--g", label = "Validation Accuracy")

plt.title("Training & Validation Accuracy and Loss")
plt.legend()

y_pred = model.predict(X_test)

y_pred = np.argmax(y_pred, axis=1)

y_pred

y_test

y_test = np.argmax(y_test,axis=1)

y_test

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(7,5))

ax = sns.heatmap(cm,fmt='d', annot=True, cmap='Greens')

ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');
plt.show()
